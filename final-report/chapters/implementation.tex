%!TEX root = ../report.tex

The purpose of this chapter is to describe the implementation of the system. This chapter first begins by introducing the final system visualisations, which provides a brief overview of the implementation and their differences. Following the introduction, the rest of this chapter is structured such that the implementation of each system feature is described. The first item to be discussed is the dataset and navigation techniques, followed by the surface and data point displays. Then the information displays and skybox details are outlined. Finally, the implementation of the drawer and its filtering and configuration components are revealed before moving onto the implementation of the system evaluation.

\section{System} {
\label{sec:system}

	The first visualisation for the system saw the implementation of a cuboid surface which began with a generated dataset, before transitioning to real data. This visualisation has been presented in Figure~\ref{fig:cuboid_surface} and features a population dataset projected from the world map. The implementation for this visualisaton loads the dataset at application startup and processes the information such that it is stored in a Backbone collection. The processing of the dataset involves transforming the $x$, $y$ and $z$ values of the data, which are specified as $longtitude$, $latitude$ and $population$ respectively, into the THREE.js coordinate system. A $coordinate$ and $magnitude$ field is also added during processing, so that these values can be referenced when performing calculations in the \texttt{Point} class. For instance, longitude and latitude determine the initial position of the point before being projected, while the population indicates its magnitude. Once the collection has been populated with models, the visualisation is created. The visualisation contains the cuboid surface, data points and a projection to be applied to all points. The details for the creation of the surface, the data points and their projection has been outlined in Section~\ref{sec:surface} and~\ref{sec:data_point_display}.

	\input{figures/implementation/system/cuboid}

	The second visualisation modified the surface and projection used in the previous implementation, which have been described in Section~\ref{sec:surface} and~\ref{sec:data_point_display}. This visualisation also used a population dataset, which can be seen in Figure~\ref{fig:sphere_surface} and hence the same processing techniques were utilised during application startup.

	\input{figures/implementation/system/sphere}

	The final implementation for this system integrates a student progress dataset for teaching analytics using a grid surface. This visualisation fulfils one of the goals and deliverables of the project and can be seen in Figure~\ref{fig:grid_surface}. This visualisation required alternate processing techniques for implementation. First of all, when the dataset was processed the $x$, $y$ and $z$ values were instead mapped to $group$, $week$ and $progress$. Since this dataset cannot map keys to the position of a point, as the data may include strings, the position had to be calculated using the $x$, $y$ and $z$ values. This is unlike the population dataset, which was able to map longitude and latitude to a position. Finally, there are two significant differences between this visualisation and the previous two that have been outlined. The first is that there is no skybox displayed in the scene and the second is that the surface does not utilise textures or shaders.

	\input{figures/implementation/system/grid}
	
}

\section{Datasets} {
\label{sec:datasets}

	\subsection{Population dataset} {
	\label{sec:population_dataset}

		The GeoNames database was used as the basis for the population dataset. This data was preprocessed with a Python script and converted into a JSON structure, so it could be used with the visualisations. One issue with the dataset is that it does not contain the name of the country. This was considered an important feature, as it would enable users to identify the country associated with a data point with relative ease. This information was added by loading a separate JSON dataset that contained a list of country names and their code, and mapping each country code to its corresponding name. The GeoNames dataset contained country codes, so the country name could be accessed with this map and added to the final output for each city. Alongside this processing, unwanted information such as elevation and administration codes were filtered out and specific strings were converted to numbers before the output was exported to a JSON file.

	}

	\subsection{Student progress dataset} {
	\label{sec:student_progress_dataset}

		The data used to monitor student progress can be retrieved from the server used in the group project. During application startup, an AJAX request is performed to fetch this data from the live system.

	}

	\subsection{Structure} {
	\label{sec:dataset_structure}

		The structure used in both the population and student progress datasets has been shown in Figure~\ref{fig:datasets} below.

		\input{figures/implementation/datasets}

	}

}

\section{Navigation} {
\label{sec:navigation}

	The navigation techniques that the user can interact with are pan, rotate and zoom. This functionality was implemented in a single module and utilised mouse events to detect when the user was scrolling or pressing the left or right mouse button. It is important to note that Three.js uses a right-handed coordinate system, as shown in Figure~\ref{fig:threejs_coordinate_system}.

	\input{figures/implementation/threejs_coordinate_system}

	\subsection{Pan} {
	\label{sec:pan}

		This interaction is initiated when a \texttt{mousedown} event is fired on the canvas, followed by a \texttt{mousemove} event bound to the \texttt{window}. This simulates drag when pressing the left mouse button.

		As the user moves their pointer, the camera is translated in the x and y direction. This calculation relies on converting screen coordinates to world coordinates and normalising the value so it is a ratio of the viewport height, instead of both the width and height.

		Once the translation to the camera has been applied, the \texttt{origin} vector needs to be updated, which is used during rotation. An updated origin ensures there is no sudden movement when rotating, after panning the screen.

		Finally, when the user releases the left mouse button, a \texttt{mouseup} event is triggered which removes the event binding for \texttt{mousemove} on the \texttt{window}. 

	}

	\subsection{Rotate} {
	\label{sec:rotate}

		Rotation uses the same event chain as panning, except instead of listening to the left mouse click, it listens to the right.

		To rotate the camera, the cartesian coordinates need to be calculated from spherical coordinates, using the following formula in a right-handed mathematics system:

		\input{formulas/implementation/spherical_to_cartesian}
	
	}

	\subsection{Zoom} {
	\label{sec:zoom}

		This navigation technique begins when the user scrolls with their mouse, triggering a \texttt{wheel} event in the browser. A ratio of the delta value is taken and the camera is then translated by this amount.
	
	}

}

\section{Surface} {
\label{sec:surface}

	\begin{sloppypar}
		A surface consists of a \texttt{THREE.Mesh} and uses either a \texttt{THREE.BoxGeometry} or \texttt{THREE.SphereGeometry} for its geometry. The material used in both the cuboid and sphere surface is a \texttt{THREE.ShaderMaterial}, which facilitates the configuration of midtone effects and other uniforms. The entry point for the shader is demonstrated below.
	\end{sloppypar}

	\input{code/implementation/surface_fragment}

	The above snippet of code applies a colour balance effect to every point in the fragment shader that represents the surface texture. In a cuboid surface for instance, any point that is beneath the top face is set to a solid colour. This removes the appearance of a stretched texture on all other sides of the cuboid. In contrast to this, the grid surface uses a simple \texttt{THREE.MeshBasicMaterial} as it does not contain a texture or other uniforms.

}

\section{Data point display} {
\label{sec:data_point_display}

	The data point displays were implemented by creating a \texttt{THREE.Mesh} that acts as a \texttt{Points} container for all \texttt{Point} meshes. The \texttt{Points} class is repsonsible for creating all of the data point displays, using the \texttt{Point} Backbone collection created and populated with information from the dataset during application startup. Each model in this collection specifies the initial position and magnitude of the \texttt{Point} mesh, which consists of a \texttt{THREE.BoxGeometry} and \texttt{THREE.ShaderMaterial}. Additionally, the \texttt{Points} class ensures that each \texttt{Point} appears as if it were on top of the surface, by applying either a standard for cuboids or a spherical projection for spheres.

	The standard projection simply sets the y-position of the object by some offset, in this case the height of the cuboid surface, and then converts the range of the x and z-positions so that is fits on the cuboid dimensions. Whereas the spherical projection first converts x-position of the object to $\theta$ and the z-position to $\phi$ in radians. These values are used, along with the radius of the sphere, to apply a spherical to cartesian conversion which denotes the position of the \texttt{Point}. Then, the point is rotated to face the position of the sphere and again in the x-direction so it is not tangential to the surface.

	Further, the shader used as the shader material in the \texttt{Point} class uses various uniforms to provide a multitude of configurations and effects to the user, which have been specified in Section~\ref{sec:configuration_implementation}. One important aspect of the data displays is their ability to change their appearance from a HSV colour range to a gradient colour scheme, which can be seen in Figure~\ref{fig:data_point_displays} below. This has been completed with a simple fragment shader that changes which scheme to use for the display of the data points. The following code demonstrates the main entry point of this shader:

	\input{code/implementation/hybrid_fragment}

	\input{figures/implementation/data_display}

}

\section{Information display} {
\label{sec:information_display}

	The information display utilises a \texttt{THREE.Raycaster} and a Handlebars template for displaying model information. The raycaster is updated on each render loop and is fed a series of \texttt{Point} meshes to check if the normalised mouse coordinates intersect with any data points. These intersections are listened to in the \texttt{Information} view controller, which is responsible for updating the content and visibility of the information display element. A single element has been used to display this information as the creation of DOM elements is incredibly inefficient, especially because this would entail creating an element for each intersection at run-time. When an intersection exists, the element is displayed and its HTML is updated with its model data through Handlebars. Further, the \texttt{left} and \texttt{top} position of the element is updated to match the mouse coordinates. The position of the element is improved by calculating the quadrant in which the coordinate lies and adjusting the position such that the display is always towards the centre of the screen. This prevents the information from being clipped off when the user hovers at the edge of the screen. An example of this and the design of the information display hover effect can be seen in Figure~\ref{fig:information_display}.

	\input{figures/implementation/information_display}

}

\section{Skybox} {
\label{sec:skybox}

	The skybox was generated using \href{http://alexcpeterson.com/spacescape/}{Spacescape}, a program designed for creating space skyboxes with stars and nebulas. Once the skybox was created, the images were exported as six individual images. The formation of these images can be seen in Figure~\ref{fig:skybox}.

	\input{figures/implementation/skybox}

	\begin{sloppypar}
		The implementation of the skybox was a simple process. This process involved loading each side of the cuboid as a \texttt{THREE.Texture} and assigning it as a \texttt{map} in a \texttt{THREE.MeshBasicMaterial} object. Each basic material was stored in an array, so that the skybox mesh could be created using a \texttt{THREE.BoxGeometry} and \texttt{THREE.MeshFaceMaterial}. It is important that the skybox is static during navigation, particularly so that the underlying cuboid structure of the skybox is not noticeable and appears more realistic to the user. This was accomplished by listening to the \texttt{pan}, \texttt{zoom} and \texttt{rotate} events in the mouse controls, and updating the position of the skybox to reflect that of the camera.
	\end{sloppypar}

}

\section{Drawer menu} {
\label{sec:drawer}

	The drawer menu is located on the left side of the system and is initially closed to maximise the visualisation viewing area. It has been built with pure CSS, using a checkbox that alters and transitions the position of the menu when the checkbox is checked. This interface has been shown in Figure~\ref{fig:drawer} below.

	\input{figures/implementation/drawer}

}

\section{Filtering} {
\label{sec:filtering_implementation}

	Filtering was implemented using an event-driven approach and a view controller for configuring the filters. This view controller comprises the slider and checkbox views, which were designed using Handlebars templates and populated with a Backbone model. The final design of this interface has been demonstrated in Figure~\ref{fig:filtering_interface}.

	\input{figures/implementation/filtering/interface}

	As a user adjusts the values in the slider, an \texttt{update} event is triggered. When this occurs, the event handler adjusts the minimum and maximum input to reflect the new slider widget values. Then, the Backbone collection that represents the data displays are filtered by calling the \texttt{filterBy} function with a filter function. This method is reposnsible for iterating through each model in the collection and determining if it should be filtered. A simple example of a filter function is:

	\input{code/implementation/filtering_function}

	The above function utilises closure to check if the property associated with the slider is within the specified minimum and maximum bounds. If this function returns \texttt{true}, the model is added to a filtered collection. Once the collection has been iterated through, the \texttt{filterBy} function triggers a \texttt{filter} event with the filtered collection. This event is handled through other classes and ultimately modifies the visibility of the data display mesh based on the results of filtering.

	A similar process occurs when the user enters a value into the minimum or maximum inputs. A \texttt{keyup} event is bound to both inputs and a timer is in place to enforce a filtering delay. This delay ensures that filtering is processed as required, when the user has stopped typing, in order to reduce performance issues. When the user stops typing, the slider values are updated to match the input and filtering then proceeds as normal.

	As previously mentioned, the checkboxes represent what information is available to the user when hovering on a data display. The state of visibility for any given property is configured through a custom Handlebars helper method. This helper method is called when the information display template is updated, which is every time the user hovers on a data display. The helper method simply checks if a property is currently in a filtered list and displays the property when it is not a member of this list. So in order to configure the visibility of properties in the information display, a \texttt{change} event is bound to each chexkbox that updates the contents of the filtered list.

	The sequence of images displayed in Figure~\ref{fig:filtering_comparison} presents a comparison between the results of filtering for both data displays and information displays. From this, it can be seen that the user activities outlined in Section~\ref{sec:user_actions} have the potential to be fulfilled more quickly when there is less data to navigate through.

	\input{figures/implementation/filtering/comparison}

}

\section{Configuration} {
\label{sec:configuration_implementation}

	Real-time configurations are best achieved by using shaders. Shaders are computer programs that perform shading on a graphics processing unit (GPU), making them highly efficient and well suited to parallel processing~\footnote{\bibentry{gerdelan2014shaders}}. Three.js provides abstracted materials that use shaders in the background, but this method does not easily facilitate highly customisable configurations or filter effects. Therefore, custom shaders were designed and implemented for the system to maximise efficiency and flexibility. An example of the available effects that were implemented in the system is shown in Figure~\ref{fig:shaders}.

	\input{figures/implementation/shaders}

	These configurations can be adjusted in real-time with \href{http://workshop.chromeexperiments.com/}{dat.GUI}, a lightweight GUI for changing JavaScript variables in real-time. This tool is easy to use, setup and can modify shader uniforms automatically or by implementing \texttt{onChange} event handlers. dat.GUI can constrain input data and provides widgets for modifying values, colours and combo boxes. While this tool is great for modifying data on the fly, it has an outdated interface that does not always adapt well to particular colour schemes and designs. For this reason, the dat.GUI styles were modified to seamlessly integrate with the current system and the Material Design standards. The differences in design can be compared in Figure~\ref{fig:dat_gui} below.

	\input{figures/implementation/dat_gui}

	The design for these configurations were continually refined during implementation. Initially, the dat.GUI sliders were to remain unchanged. However, these sliders proved to be inconsistent in regards to the colour scheme and filter design. Furthermore, the bold folder colours were eventually removed to reflect drawer layouts that conform to using light navigation colours, hover effects, and left floated icons.

}

\section{System evaluation} {
\label{sec:system_evaluation}

	As discussed in Section~\ref{sec:evaluation_design}, a user study and performance analysis has been undertaken as a way to measure the usability and effectiveness of the visualisations that have been implemented in this project. The details for these evaluations have been described in Section~\ref{sec:user_study} and \ref{sec:performance_analysis} respectively.

	The system evaluations were performed on an MSI GS60 Ghost Pro 4K 15.6in Gaming Notebook with 16GB RAM and an NVIDIA GeForce GTX 970M dedicated graphics card. The visualisations were loaded in an offline environment using the high performance mode offered in Windows 8.1 to enhance the user experience and minimise performance issues.

	\subsection{User study} {
	\label{sec:user_study}

		Prior to commencing the user study, there were a couple user issues that were observed throughout the development process. As a result, it was expected that users may experience difficulty navigating the population globe and may be confused as to the purpose of the checkboxes in the sidebar.

		There were eight male participants who volunteered to undertake this user study. The participants were aged between 22-29 and are enrolled in the final year project. All participants use computers on a daily basis and are familiar with navigating websites and using common functionality such as filtering.

		The process began by asking the participant to complete a consent form. A brief overview of each visualisation and the dataset they represent was provided after the user completed this form. The participant was given task instructions and encouraged to ask questions throughout the evaluation. They were then able to experiment with the visualisations in any order and asked to complete a questionnaire. On average the participant took approximately five minutes to complete the study.

	}

	\subsection{Performance analyis} {
	\label{sec:performance_analysis}

		% \todo{performance slow with large data mention filtering and configuration}

		The performance analyis was conducted by carrying out manual performance testing, which has been outlined in Section~\ref{sec:performance_testing}. Each test was executed for a dataset size of \dots

		\todo{figure out sizes, 100, 500, 1000, 5000, 10000, 20000, five times and an average was recorded to indicate the time for the metric.}

		confirmed estimate values with stopwatch test.

	}


}
